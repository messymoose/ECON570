{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Data Wrangling III: Transformations and Groupby\n",
    "\n",
    "Files needed = ('atussum_2017.dat', 'movies.csv')\n",
    "\n",
    "Let's continue practicing techniques for manipulating data into forms that are amenable to analysis. In this section, we will cover: \n",
    "\n",
    "1. `.replace()` for recoding variables\n",
    "3. `.map()` for working element-wise on DataFrames\n",
    "4. String methods for working with strings in DataFrames\n",
    "5. `.groupby()` for performing group-specific calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.chdir('/Users/jackson/Documents/ECON570')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### American Time Use Survey (ATUS)\n",
    "Let's work with the ATUS data again. To refresh your memory, the Bureau of Labor Statistics oversees the [American Time Use Survey](https://www.bls.gov/tus/overview.htm), which asks a sample of Americans to complete detailed diaries keeping track of each minute of their day. \n",
    "\n",
    "Follow this link [www.bls.gov/tus/data/datafiles_2017.htm](https://www.bls.gov/tus/data/datafiles_2017.htm) to the page for the 2017 survey. Download the **ATUS 2017 Activity summary file (zip)** file located in the **2017 Basic ATUS Data Files** section of the page. Alternatively, download it directly [www.bls.gov/tus/datafiles/atussum_2017.zip](https://www.bls.gov/tus/datafiles/atussum_2017.zip). \n",
    "\n",
    "Unzip the file. We are looking for `atussum_2017.dat`. It is a comma separated file (even though it has a '.dat' extension). Let's get it loaded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables\n",
    "\n",
    "This data set has 421 variables! That's too many for us today. Let's just keep some demographic data and some data about working and sleeping. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables2 = {'TEAGE':'age', 'TESEX':'sex', 'PEEDUCA':'edu', 'GTMETSTA':'metro', 'TELFS':'employ', \n",
    " 'TUDIARYDAY':'day', 't050101':'work_main', 't050102':'work_other', 't010101':'sleep', 't050201':'work_soc', 't010102':'no_sleep'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "atus_small = pd.read_csv('data/atussum_2017.dat', usecols=variables2.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "atus_small.rename(columns=variables2, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10223 entries, 0 to 10222\n",
      "Data columns (total 11 columns):\n",
      " #   Column      Non-Null Count  Dtype\n",
      "---  ------      --------------  -----\n",
      " 0   age         10223 non-null  int64\n",
      " 1   sex         10223 non-null  int64\n",
      " 2   edu         10223 non-null  int64\n",
      " 3   metro       10223 non-null  int64\n",
      " 4   employ      10223 non-null  int64\n",
      " 5   day         10223 non-null  int64\n",
      " 6   sleep       10223 non-null  int64\n",
      " 7   no_sleep    10223 non-null  int64\n",
      " 8   work_main   10223 non-null  int64\n",
      " 9   work_other  10223 non-null  int64\n",
      " 10  work_soc    10223 non-null  int64\n",
      "dtypes: int64(11)\n",
      "memory usage: 878.7 KB\n"
     ]
    }
   ],
   "source": [
    "atus_small.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>edu</th>\n",
       "      <th>metro</th>\n",
       "      <th>employ</th>\n",
       "      <th>day</th>\n",
       "      <th>sleep</th>\n",
       "      <th>no_sleep</th>\n",
       "      <th>work_main</th>\n",
       "      <th>work_other</th>\n",
       "      <th>work_soc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>728</td>\n",
       "      <td>0</td>\n",
       "      <td>450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>385</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>570</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>525</td>\n",
       "      <td>0</td>\n",
       "      <td>480</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>756</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  edu  metro  employ  day  sleep  no_sleep  work_main  work_other  \\\n",
       "0   34    2   39      1       1    1    728         0        450           0   \n",
       "1   28    2   40      1       5    7    385         0          0           0   \n",
       "2   15    1   35      1       5    4    570         0          0           0   \n",
       "3   46    1   39      1       1    2    525         0        480           0   \n",
       "4   85    1   44      1       1    7    756         0          0           0   \n",
       "\n",
       "   work_soc  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atus_small.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks pretty good. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## replace( ) \n",
    "\n",
    "The sex variable is coded 1 for male and 2 for female. I do not want to have to remember that!\n",
    "\n",
    "The `replace()` method replaces one value for another. One syntax is \n",
    "```python\n",
    "atus_small['sex'] = atus_small['sex'].replace(1, 'male')\n",
    "```\n",
    "but a more powerful one passes a dict or a list.\n",
    "```python\n",
    "atus_small['sex'] = atus_small['sex'].replace({1:'male', 2:'female'})\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_codes = {1:'male', 2:'female'}\n",
    "atus_small['sex'] = atus_small['sex'].replace(sex_codes)\n",
    "atus_small.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also recode `edu`, which holds the highest level of education obtained. What are the unique values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atus_small['edu'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do all these codes represent? I read the documentation..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's group all codes less than 39 as \"less than high school\"\n",
    "atus_small.loc[atus_small['edu'] < 39, 'edu'] = 0\n",
    "# define a dictionary\n",
    "edu_codes = {0:'less than high school', 39:'high school', 40:'some college', 41:'associate', 42:'associate', 43:'bachelor', \n",
    "              44:'master', 45:'prof', 46:'phd'}\n",
    "# replace\n",
    "atus_small['edu'] = atus_small['edu'].replace(edu_codes)\n",
    "atus_small.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply a function to a Series or DataFrame: map()\n",
    "\n",
    "We can apply functions to the individual elements in a Series or a DataFrame using `.map()`. These can be built-in functions, or user-defined functions (including lambda functions).\n",
    "\n",
    "This is quite powerful. For illustration, let's create a new variable that is the log of `1 + 'sleep'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atus_small['log1p_sleep']=atus_small['sleep'].map(np.log1p)\n",
    "atus_small.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we could have just as easily used `np.log1p(atus_small['sleep'])` or `np.log(atus_small['sleep']+1)` in this case.\n",
    "\n",
    "*Side note*: Why is there a separate numpy function for `log(x+1)`? Let's check the [docs](https://numpy.org/doc/2.1/reference/generated/numpy.log1p.html). Looks like this is useful if `x` is very small.\n",
    "\n",
    "We can apply the same function to multiple columns of a DataFrame using `map()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An aside about np.log1p\n",
    "x=1e-50\n",
    "same = 1+x == 1\n",
    "print('same?',same)\n",
    "print('np.log1p(x)=',np.log1p(x))\n",
    "print('np.log(1+x)=',np.log(1+x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lambda functions\n",
    "\n",
    "Python offers a simple way to create anonymous, single expression functions in a single line of code. These are called \"lambda functions.\" Here's a simple example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "double_sum = lambda a , b : (a + b) * 2\n",
    "print(double_sum(5,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic syntax for any lambda function is:\n",
    "\n",
    "```python\n",
    "function_name = lambda arguments : expression\n",
    "```\n",
    "The following lambda function converts minutes to hours for all of the time variables in our ATUS DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can map to several columns at once.\n",
    "time_vars=['sleep', 'no_sleep','work_main','work_other','work_soc']\n",
    "atus_small[time_vars] = atus_small[time_vars].map(lambda x: x / 60)\n",
    "atus_small.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String methods\n",
    "\n",
    "These are analogous to the string methods in standard python, but they have been optimized for DataFrames. These *vectorized string methods* work element-wise over an entire column. The method call looks like\n",
    "\n",
    "```python\n",
    "data['var'].str.method()\n",
    "```\n",
    "\n",
    "where `.str.method( )` is the method we are applying. A list of vectorized string methods is available in the [documentation here](https://pandas.pydata.org/pandas-docs/stable/user_guide/text.html#method-summary). Below, we try a few out. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MovieLens data set\n",
    "\n",
    "We are going to work with the [MovieLens](https://grouplens.org/datasets/movielens/) *ml-latest-small* dataset. The GroupLens organization released this data. It is meant to help build recommendation algorithms, like the ones you see in Netflix or Spotify. \\[In 2006, [Netflix started a contest](https://en.wikipedia.org/wiki/Netflix_Prize), with a $1 mil. reward, for an algorithm that could beat their own.\\] They have other ratings datasets, too, on music, jokes, and books.  \n",
    "\n",
    "An observation is a movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('movies.csv')\n",
    "movies.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### str.contains( )\n",
    "The genres are mixed together. Let's get all the comedies. The `.contains( )` method returns a bool Series with True for observations in which the string contains the search term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['genres'].str.contains('Comedy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(movies.shape)\n",
    "comedies = movies[movies['genres'].str.contains('Comedy')]\n",
    "print(comedies.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### str.split( )\n",
    "This method splits the string up at the delimiter that is passed to `.split( )`. It returns a list of each chunk that falls between the delimiter. \n",
    "\n",
    "This could be useful processing name data that come in the form: last,first or city,state. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The movie genres are separated with the '|' character. \n",
    "# DataFrames can have columns of lists!\n",
    "movies['genre_split'] = movies['genres'].str.split('|')\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### str.join ( )\n",
    "Put strings together. Separate the pieces with a delimiter of your choosing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "movies['with_commas'] = movies['genre_split'].str.join(', ')\n",
    "movies.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice:\n",
    "\n",
    "Take a few minutes and try the following. Feel free to chat with those around you if you get stuck. I am here, too. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data does not have a column for the year the movie was released. Let's create one. The year the movie was released is in the title string.    \n",
    "\n",
    "0. Reload 'movies.csv'\n",
    "1. Use `.str.strip()` ([docs](https://pandas.pydata.org/pandas-docs/version/0.24.2/reference/api/pandas.Series.str.strip.html)) to remove any leading or trailing spaces from 'title'.\n",
    "\n",
    "1. Extract the four-digit year from the titles and put them into a new column named 'year'.  \n",
    "\n",
    "Notice that the year, including the parentheses, is always the last 6 digits of the title. You might try `str.slice()` and work with negative indexes to count from the end of 'title' (with index -1 representing the last digit).\n",
    "\n",
    "If there is any extra space at the end of a title, it will mess up my algorithm! That's why we strip the extra spaces first. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. There are 12 movies that do not have a year in their title. Find them in your DataFrame. You might try the `str.isdigit()` [(doc)](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.isdigit.html#pandas.Series.str.isdigit) method to see if the year you extracted in step 2. is numeric. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groupby\n",
    "\n",
    "We often want to know how groups differ. Do workers with econ degrees make more than workers with history degrees? Do men live longer than women? Does it matter how much education you have? \n",
    "\n",
    "Pandas provides the `groupby()` method to ease computing statistics by group ([docs](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html)). This kind of method shows up in many data-oriented computing languages and packages. The idea is summed up as \n",
    "\n",
    "> split-apply-combine\n",
    "\n",
    "Here is the canonical [illustration](https://www.oreilly.com/library/view/learning-pandas/9781783985128/ch09s02.html). The big idea is to \n",
    "\n",
    "1. **Split** the data up into groups. The groups are defined by *key* variables.\n",
    "2. **Apply** some method or function to each group: mean, std, max, etc. This returns a smaller bit of data, often just one number.\n",
    "3. **Combine** the results of the 'apply' from each group into a new data structure.\n",
    "  \n",
    "  \n",
    "Apply-split-combine is an incredibly powerful feature of pandas. We will cover the basics here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split-apply-combine\n",
    "\n",
    "Let's use our split-apply-combine method in one simple line of code:\n",
    "\n",
    "1. Split: We pass `.groupby()` a *key* which tells the method which variable(s) to, well, group by. (We will group by `edu` for now.)\n",
    "2. Apply and Combine: We want to compute some statistic by group. (We will use the `.mean()` for now.)\n",
    "\n",
    "We typically also want to select certain columns to perform the calculations. (Here, we'll consider `sleep`, `no_sleep`, `work_main`, `work_other`, and `work_soc`. **We also have to keep our groupby variable(s). This means we have to keep `edu` as well!**)\n",
    "\n",
    "Let's give it a try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the cols we want from the df before using the groupby. Remember to keep the grouping variable, too.\n",
    "timeuse_means = atus_small[['sleep','no_sleep','work_main','work_other','work_soc','edu']].groupby('edu').mean()\n",
    "timeuse_means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregation methods\n",
    "\n",
    "Some common aggregation methods include: `.mean()`, `.sum()`, `.std()`, `.describe()`, `.min()`, `.max()`, but there are many more. Any function that returns a scalar will work. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Several statistics at once\n",
    "Once we have grouped our data, we have been applying methods to compute a single statistic: `mean()`, `count()`,...\n",
    "\n",
    "We now introduced the `.agg()` method, which lets us compute several moments at once&mdash;you can even pass it a user-defined function or a lambda function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agg() lets us compute many stats at once\n",
    "mult_stats = atus_small[['sleep','work_main','edu']].groupby('edu').agg(['count', 'mean', 'median', 'std', 'max'])\n",
    "mult_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a multiIndex on the columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### groupby( ) with many keys\n",
    "Can we group by several keys? You know we can. Let's compute the means and the medians of the DataFrame this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ed_sex_stats = atus_small[['edu','sex','sleep','work_main']].groupby(['edu','sex']).agg(['mean','median'])\n",
    "ed_sex_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! The MultiIndex in rows is the groupby, and the multiIndex in the columns gives the two moments we specified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice:\n",
    "\n",
    "The `.quantile()` method ([docs](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.quantile.html)) computes quantiles from the data. (e.g., `.quantile(0.5)` computes the median, or the 50th quantile)\n",
    "\n",
    "1. Let's look at a measure of variation in sleep time \n",
    "   \n",
    "    A. Compute the 75th quantile for 'sleep' for each edu category. Name the new DataFrame 'q75'.      \n",
    "    B. Compute the 25th quantile for 'sleep' for each edu category. Name the new DataFrame 'q25'.\n",
    "\n",
    "For each type, compute the difference between the 75 percentile and the 25 percentile. \n",
    "\n",
    "This is sometimes called the *inter-quartile range*. It is a measure of the variability of a variable. It is less sensitive to outliers than the standard deviation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Calculate the mean, median, standard deviation, and inter-quartile range of sleep, grouped by edu and sex, in a single line of code. \\[Hint: Use a lambda function!\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try at home: \n",
    "How would you fix the name of your new column in the resulting DataFrame?"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Attachments",
  "kernelspec": {
   "display_name": "econ570",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
